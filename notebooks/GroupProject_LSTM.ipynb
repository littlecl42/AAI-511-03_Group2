{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/littlecl42/AAI-511-03_Group2/blob/main/notebooks/GroupProject_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Team Project Introduction\n",
        "### Introduction\n",
        "\n",
        "Music is a form of art that is ubiquitous and has a rich history. Different composers have created music with their unique styles and compositions. However, identifying the composer of a particular piece of music can be a challenging task, especially for novice musicians or listeners. The proposed project aims to use deep learning techniques to identify the composer of a given piece of music accurately.\n",
        "\n",
        "### Objective\n",
        "\n",
        "The primary objective of this project is to develop a deep learning model that can predict the composer of a given musical score accurately. The project aims to accomplish this objective by using two deep learning techniques: Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN).\n",
        "\n",
        "### Project Timeline\n",
        "\n",
        "- Module 2 (by the end of Week 2): The course instructor will group students into teams of two to three members. Canvas, USD Email, or Slack can be used to find prospective team members.\n",
        "- Module 4 (by the end of Week 4): Each team's representative will need to submit the \"Team Project Status Update Form.\"\n",
        "- Module 7 (by the end of Week 7): Each team should submit deliverables for the course project in the final week:\n",
        "\n",
        ">1.  Project Report\n",
        ">1. Project Notebook\n",
        "\n",
        "It is critical to note that no extensions will be given for any of the final projects' due dates for any reason, and final projects submitted after the final due date will not be graded.\n",
        "Dataset\n",
        "\n",
        "The project will use a dataset consisting of musical scores from various composers. The dataset Download datasetwill contain MIDI files and sheet music of compositions from well-known classical composers like Bach, Beethoven, Chopin, Mozart, Schubert, etc. The dataset should be labeled with the name of the composer for each score.\n",
        "\n",
        "### Dataset\n",
        "The project will use a dataset consisting of musical scores from various composers. Download the dataset from Kaggle websiteLinks to an external site..\n",
        "\n",
        "The dataset contains the midi files of compositions from well-known classical composers like Bach, Beethoven, Chopin, and Mozart. The dataset should be labeled with the name of the composer for each score. Please only do your prediction only for below composers, therefore you need to select the required composers from the given dataset above.\n",
        "\n",
        ">1. Bach\n",
        ">1. Beethoven\n",
        ">1. Chopin\n",
        ">1. Mozart\n",
        "\n",
        "### Methodology\n",
        "\n",
        "The proposed project will be implemented using the following steps:\n",
        "\n",
        "1. Data Collection: Data is collected and provided to you.\n",
        "1. Data Pre-processing: Convert the musical scores into a format suitable for deep learning models. This involves converting the musical scores into MIDI files and applying data augmentation techniques.\n",
        "1. Feature Extraction: Extract features from the MIDI files, such as notes, chords, and tempo, using music analysis tools.\n",
        "1. Model Building: Develop a deep learning model using LSTM and CNN architectures to classify the musical scores according to the composer.\n",
        "1. Model Training: Train the deep learning model using the pre-processed and feature-extracted data.\n",
        "1. Model Evaluation: Evaluate the performance of the deep learning model using accuracy, precision, and recall metrics.\n",
        "1. Model Optimization: Optimize the deep learning model by fine-tuning hyperparameters.\n",
        "\n",
        "### Deliverables\n",
        "\n",
        "1. Project Report: A comprehensive documentation/report that describes the methodology, data pre-processing steps, feature extraction techniques, model architecture, and training process for reproducibility and future reference. Write your technical report in APA 7 style (here is a Sample Professional Paper format to follow). Please submit the report in PDF format and use the File naming convention DeliverableName-TeamNumber.pdf; for example, Project_Report-Team1.pdf\n",
        "\n",
        "Your report should:\n",
        "contain a reference list that includes any external sources, libraries, or frameworks used during the project, including proper citations or acknowledgments.\n",
        "\n",
        "include a concluding section or markdown cell that summarizes the project, highlights key findings, and suggests any potential future improvements or extensions to the work.\n",
        "\n",
        "2. Project Notebook: A Jupyter Notebook file (.ipynb) that contains the entire project code, including data pre-processing, feature extraction, model building, training, evaluation, and any additional analysis or visualizations performed during the project.\n",
        "\n",
        "This deliverable will be exported from a Jupyter Notebook and submitted as a PDF or HTML file.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "The proposed project aims to use deep learning techniques to accurately predict the composer of a given musical score. The project will be implemented using LSTM and CNN architectures and will involve data pre-processing, feature extraction, model building, training, and evaluation. The final model can be used by novice musicians, listeners, and music enthusiasts to identify the composer of a musical piece accurately.\n",
        "\n",
        "### Power Usage for this Project\n",
        "\n",
        "You can use Google Colab GPU and TPU in case you need more computation power. Change your runtime in Google Colab notebook to GPU or TPU.\n",
        "Another option is to buy the subscription in case you need more computational power (recommended).\n",
        "\n",
        "Please follow this link to do so: Google Colab Pro+.\n",
        "NOTE: Team members may not get the same grade on the Final Team Project, depending on each team member's level of contribution.\n",
        "\n",
        "To understand how your work will be assessed, view the assignment rubric on the Final Team Project page.\n",
        "\n"
      ],
      "metadata": {
        "id": "Bix0Kn-bTtNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pretty_midi\n"
      ],
      "metadata": {
        "id": "f8z9HA5Fbpjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Required libs for the project\n",
        "import kagglehub\n",
        "import pretty_midi\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import re\n",
        "import difflib"
      ],
      "metadata": {
        "id": "bkkAxNGqbNmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"blanderbuss/midi-classic-music\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "midi_path = path"
      ],
      "metadata": {
        "id": "JuFW7u5unC8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KmBaNCo-nEtL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "T9jzngRfnEw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "known_composers = [\n",
        "    \"Bach\", \"Mozart\", \"Beethoven\", \"Chopin\", \"Tchaikovsky\", \"Handel\", \"Schubert\",\n",
        "    \"Haydn\", \"Brahms\", \"Liszt\", \"Mendelssohn\", \"Debussy\", \"Ravel\", \"Grieg\", \"Dvorak\",\n",
        "    \"Vivaldi\", \"Stravinsky\", \"Rachmaninoff\", \"Mahler\", \"Shostakovich\", \"Alkan\", \"Albeniz\",\n",
        "    \"Ambroise\", \"Arensky\", \"Arndt\", \"Bacewitz\"\n",
        "]\n",
        "\n",
        "def load_midi_files(directory):\n",
        "    midi_data = []\n",
        "    bad_files = []  # Track bad files\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.lower().endswith((\".mid\", \".midi\")):\n",
        "                try:\n",
        "                    full_path = os.path.join(root, file)\n",
        "                    midi = pretty_midi.PrettyMIDI(full_path)\n",
        "                    midi_data.append((full_path, file, midi))\n",
        "                except Exception:\n",
        "                    bad_files.append(file)\n",
        "                    continue\n",
        "    return midi_data, bad_files"
      ],
      "metadata": {
        "id": "reOXALSYnDA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_composer_from_path(full_path):\n",
        "    parts = os.path.normpath(full_path).split(os.sep)\n",
        "    for part in reversed(parts[:-1]):  # Exclude filename\n",
        "        for composer in known_composers:\n",
        "            if composer.lower() in part.lower():\n",
        "                return composer\n",
        "    return \"Unknown\""
      ],
      "metadata": {
        "id": "LfwnZwmjnDQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(midi_dataset):\n",
        "    rows = []\n",
        "    for full_path, filename, midi in midi_dataset:\n",
        "        try:\n",
        "            duration = midi.get_end_time()\n",
        "            num_instruments = len(midi.instruments)\n",
        "\n",
        "            tempo_changes = midi.get_tempo_changes()\n",
        "            tempo = float(np.mean(tempo_changes[1])) if len(tempo_changes[1]) > 0 else np.nan\n",
        "\n",
        "            notes = [note.pitch for instrument in midi.instruments for note in instrument.notes if not instrument.is_drum]\n",
        "            avg_pitch = np.mean(notes) if notes else np.nan\n",
        "            note_density = len(notes) / duration if duration > 0 else 0\n",
        "\n",
        "            composer = extract_composer_from_path(full_path)\n",
        "\n",
        "            rows.append({\n",
        "                \"filename\": filename,\n",
        "                \"composer\": composer,\n",
        "                \"duration\": duration,\n",
        "                \"num_instruments\": num_instruments,\n",
        "                \"tempo\": tempo,\n",
        "                \"avg_pitch\": avg_pitch,\n",
        "                \"note_density\": note_density,\n",
        "                \"notes\": notes\n",
        "                'note_sequence': pitches  # raw note sequence as a list of integers\n",
        "        }\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "zOrkuvJshr4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "midi_dataset, bad_files = load_midi_files(midi_path)\n",
        "print(f\"Loaded {len(midi_dataset)} good MIDI files.\")\n",
        "print(f\"Skipped {len(bad_files)} broken files.\")"
      ],
      "metadata": {
        "id": "5s9Ch3sdlile"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = extract_features(midi_dataset)"
      ],
      "metadata": {
        "id": "BBB5ZaeDllX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "composer_counts = df[\"composer\"].value_counts()\n",
        "print(composer_counts)"
      ],
      "metadata": {
        "id": "BnCQHZj6g74y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only the selected composers\n",
        "df = df[df[\"composer\"].isin([\"Bach\", \"Beethoven\", \"Chopin\", \"Mozart\"])].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "m5kUREWRnnvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "composer_counts = df[\"composer\"].value_counts()\n",
        "print(composer_counts)"
      ],
      "metadata": {
        "id": "rah_cPpioCbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "W-6PIa2KoeJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show basic summary of the data\n",
        "df.info()\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "vzmBZqXnog5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of MIDI files per composer\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(data=df, x=\"composer\", palette='Set2')\n",
        "plt.title(\"Number of MIDI Files per Composer\")\n",
        "plt.xlabel(\"Composer\")\n",
        "plt.ylabel(\"Number of Files\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R0YU6wYarQJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of Duration by Composer\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.boxplot(data=df, x=\"composer\", y=\"duration\", palette='Set2')\n",
        "plt.title(\"Distribution of Duration by Composer\")\n",
        "plt.xlabel(\"Composer\")\n",
        "plt.ylabel(\"Duration (seconds)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ttoyr7y4rX0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of Instruments per Composer\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.violinplot(data=df, x=\"composer\", y=\"num_instruments\", inner=\"quartile\", palette=\"Set2\")\n",
        "plt.title(\"Number of Instruments per Composer\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TQvvvUQarfjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note Density (notes/sec) by Composer\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.boxplot(data=df, x=\"composer\", y=\"note_density\", palette=\"Set2\")\n",
        "plt.title(\"Note Density (notes/sec) by Composer\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N4cCrYZDrpFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Corrleation Metrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df.drop(columns=[\"filename\"]).corr(numeric_only=True), annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Feature Correlation Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g3D-Fry9sbql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How multiple features relate to each other by composer?\n",
        "sns.pairplot(df, hue=\"composer\", vars=[\"duration\", \"tempo\", \"avg_pitch\", \"note_density\"])\n",
        "plt.suptitle(\"Pairwise Feature Distributions by Composer\", y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ovt6ANs3sqfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature means + std devs for each composer:\n",
        "summary_stats = df.groupby(\"composer\")[[\"duration\", \"tempo\", \"avg_pitch\", \"note_density\"]].agg(['mean', 'std'])\n",
        "print(summary_stats)\n"
      ],
      "metadata": {
        "id": "RyXfA9XTtQ18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "id": "IJIRspmXnDgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM Model"
      ],
      "metadata": {
        "id": "n7JzFdfzeX-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prepare data arrays\n",
        "# Pad the sequences with zeros to a uniform length\n",
        "max_len = df['notes'].apply(len).max()\n",
        "padded_notes = df['notes'].apply(lambda x: x + [0] * (max_len - len(x)))\n",
        "\n",
        "X = np.stack(padded_notes.values)\n",
        "y_labels = df['composer'].values"
      ],
      "metadata": {
        "id": "nAjPs5U8cRFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Encode labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y_labels)"
      ],
      "metadata": {
        "id": "5NZDCnQfcRIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded,\n",
        "    test_size=0.2,\n",
        "    stratify=y_encoded,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "WPdWMtTxcRLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Build LSTM model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(input_dim=len(note2idx), output_dim=128, input_length=X.shape[1]),\n",
        "    layers.LSTM(128, return_sequences=False),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(len(le.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "_2TtR1tjcRN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "2ZMVXCOgcRQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate the model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.legend()\n",
        "plt.title('Training History')\n",
        "plt.show()\n",
        "\n",
        "y_pred = model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TiZGQ_w5cRTI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}